Kafka Consumer Subscribe Example

1) 
In Apache Kafka, subscribing a consumer to topics allows it to receive messages 
from those topics dynamically. Below is an example of how to use the Kafka Consumer 
API to subscribe to one or more topics.

Example Code for Subscribing to Topics

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.Arrays;
import java.util.Properties;

public class KafkaConsumerExample {
public static void main(String[] args) {
// Step 1: Configure Kafka Consumer properties
Properties properties = new Properties();
properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092"); // Kafka broker address
properties.put(ConsumerConfig.GROUP_ID_CONFIG, "example-group"); // Consumer group ID
properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());
properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest"); // Start from the earliest message

// Step 2: Create Kafka Consumer
KafkaConsumer<String, String> consumer = new KafkaConsumer<>(properties);

// Step 3: Subscribe to topics
consumer.subscribe(Arrays.asList("topic1", "topic2"));

// Step 4: Poll for messages
try {
while (true) {
ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000)); // Poll messages
for (ConsumerRecord<String, String> record : records) {
System.out.printf("Received message: Key = %s, Value = %s, Topic = %s, Partition = %d, Offset = %d%n",
record.key(), record.value(), record.topic(), record.partition(), record.offset());
}
}
} finally {
consumer.close(); // Ensure the consumer is closed
}
}
}


Explanation of the Code

Consumer Configuration: The Properties object is used to configure the Kafka consumer. 
Key configurations include the Kafka broker address, consumer group ID, deserializers 
for keys and values, and the offset reset policy.

Creating the Consumer: The KafkaConsumer object is instantiated with the configured properties.

Subscribing to Topics: The subscribe() method is used to dynamically subscribe the consumer 
to one or more topics. In this example, the consumer subscribes to topic1 and topic2.

Polling for Messages: The poll() method retrieves messages from the subscribed topics. 
The messages are processed in a loop, and details such as the key, value, topic, partition, and offset are printed.

Closing the Consumer: The close() method ensures that the consumer is properly closed, 
releasing any resources it holds.

Key Considerations

Consumer Group: Consumers in the same group share the workload by dividing partitions 
among themselves. Each partition is assigned to only one consumer in the group.

Offset Management: By default, Kafka tracks offsets for each consumer group. Ensure proper offset 
management to avoid message loss or duplication.

Error Handling: Implement error handling to manage scenarios like broker unavailability or deserialization issues.

This example demonstrates a simple and effective way to subscribe a Kafka consumer to topics and 
process messages dynamically.

==========================================
2]
props.put("enable.auto.commit", "false"); 
// disable auto commitKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
consumer.subscribe(Collections.singletonList("demo-topic"));try {
while (true) {
ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));
for (ConsumerRecord<String, String> record : records) {
System.out.printf("Processing record: value=%s, offset=%d%n", record.value(), record.offset());
}
consumer.commitSync(); // commit offsets manually
}
} finally {
consumer.close();
}

